---
title: "D2SC: Weekly Assignments"
author: "Maanav Choudhary"
date: "2024-09-13"
output: 
  html_notebook:
    toc: true
    toc_float: true
    #toc_depth: 3
---

# Initial Loading

```{r}
library(tidyverse)
library(ggdist)
```


# Week 1
In order to figure out how to load the tidyverse package, I went to the tidyverse docsumentation. I typed in "How to load tidyverse in R" in google.

I chose the first link that came up : https://tidyverse.tidyverse.org/

I then ran the code chunk to check for errors and make sure it was working.

```{r}
?tidyverse
```

tidyverse-package {tidyverse}	R Documentation
tidyverse: Easily Install and Load the 'Tidyverse'
Description
logo
The 'tidyverse' is a set of packages that work in harmony because they share common data representations and 'API' design. This package is designed to make it easy to install and load multiple 'tidyverse' packages in a single step. Learn more about the 'tidyverse' at https://www.tidyverse.org.

Author(s)
Maintainer: Hadley Wickham hadley@rstudio.com

Other contributors:

RStudio [copyright holder, funder]

See Also
Useful links:

https://tidyverse.tidyverse.org

https://github.com/tidyverse/tidyverse

Report bugs at https://github.com/tidyverse/tidyverse/issues

[Package tidyverse version 2.0.0 Index]


# Week 2

```{r}
analogyDataset <- read.csv("tidy_data/MFIndD_analogy.csv")
print(analogyDataset)
```

1. In this data set, the first column, named "qualtrics_id", contains the unqiue identifier for the particpants. 

2.

a. There are 792 rows in the data set, and 6 columns. I did not need to write a seperate code chunk for this, as printing the analogyDataset shows the dimensions of it in the description. 

```{r}
# b.
?dplyr_by
participants <- distinct(analogyDataset["qualtrics_id"])
print(participants)
```
There are 99 unqiue people in the dataset. I found this by using the dplyr function "distinct" on the particpant Ids, the size of the returned vector is the amount of people particpating in the study.

```{r}
# c
participant_trials <- analogyDataset %>%
  group_by(qualtrics_id) %>%
    summarize(max_trials = max(trial_number))

summarize(participant_trials, sd(max_trials))

```
Yes, every particpant has data from the same number of trials. I got the max of each participants trials, and took the standard deviation of them. The standard deviation being 0 represents that all participants have the same maximum number of trials. 




# Week 3

 Process.)
 
```{r, eval = FALSE}
analogyDataset %>%
  summarize(.by = qualtrics_id, .groups = response_type, el_count = n("Rel"), )
#analogyDataset %>%
  #pivot_wider(id_cols =c(qualtrics_id), names_from = match_type_1, values_from = response_type)
```
The code chunk above was one of my attempts at solving question 1. I was correct in using the summarize function, however the syntax I used in the statement was not correct. The use of .by was correct. Grouping the info by qualtrics_id was what the question wanted, and resulted in the correct result for the code chunk that was my final solution. However, I was not properly understanding the use of .groups. I was getting an error for response_type. I double checked and saw the spelling of it was correct, so I went to the help part of R studio and saw that .groups was used more for things like groping rowwise rather than by specific data. I then googled counting with summarize and saw that the sum() function was better than n() which is the function I was seeing in the help tab. After realizing that and playing around with the syntax, I was able to get the desired result from the code chunk below. 

1.)

```{r}
summarised_by_rel_matches <- analogyDataset %>%
  summarize(.by = qualtrics_id, rel = sum(response_type == "Rel", na.rm = TRUE) )
```

2.)

```{r}
summarised_by_rel_matches %>%
  ggplot(aes(x = rel))+
  geom_histogram()+
  labs(y = "Number of participants", x = "Number of trials with relational Matches")

```
I notice that the variable of relational match count is not spread in an even way. The variable is more dense around the ends. Many of the participants have either 8 relational matches, meaning they select a relational match in every trial, or 0 relational matches, meaning they select relational matches in none of the trials. 

3.)

```{r}
analogyDataset%>% 
  pivot_wider(id_cols = c(qualtrics_id), names_from = "trial_number",names_sort = TRUE,values_from = "response_type" )
```

# Week 4


```{r}
rei_dataset <- read.csv("tidy_data/MFIndD_REI.csv")
head(rei_dataset)
```
The type of the response column is char, while the type of the scored_response column is an int. The reason that the response column has type char, is because although it includes some numbers, it also contains some cells that include, "strongly agree" or other examples of non numeric entries.

2.)
```{r}
rei_dataset_adjusted <- rei_dataset %>%
  mutate(response = case_when(response == "Strongly Disagree" ~ 1.0,response == "Strongly Agree" ~ 5.0 , is.na(response) == TRUE ~ 0, TRUE ~ as.double(response)))
#Printing adjusted data to ensure it worked
rei_dataset_adjusted
```

3.)
```{r}
rei_analysis <- rei_dataset_adjusted %>%
  mutate(new_scored_response = case_when(rev_scoring == "neg" ~ 6-response, TRUE ~ response))
#Printing the data set to show the new column
rei_analysis
```
Putting out the inputs and outputs of the numbers when reverse scoring is neg to find a pattern.
1 -> 5
2 -> 4
3 ->3
4 ->2
5 ->1
After looking for a while, i noticed that 6-input is equal to the correct output for all of our possible inputs.

4.)
```{r}
accuracy <- rei_analysis%>%
summarise(all(new_scored_response == scored_response, na.rm = TRUE))
accuracy
```
I used summarize to compare the new scored response column with the one already in the data set, if they are all equal, then the code should return True. The return of True indicates that the new_scored_responsse column is correct.

# Week 5

1a.)
```{r}
rei_sub_scale_summary <- rei_analysis %>%
  group_by(qualtrics_id, sub_type ) %>%
  summarize(score = sum(new_scored_response))
rei_sub_scale_summary
```

1b.)
```{r}
rei_sub_scale_summary %>%
  ungroup() %>%
  summarise(any(is.na(score)))
```

I ungrouped here first because i was getting a response that was not correct, any() should result in one boolean yet i was getting a whole column. I went to stack overflow for this. After ungrouping, i did any() which would return TRUE if any of the score values were na. The return of false indicates that there were no NA values.

1c.)

My code did not show any values that were na, however if there were i would have to go and look back at the code for any place i could add an na.rm = TRUE to ignore the na values for that calculation and/or summary.

2.)
```{r}
analogy_rei_joint <- full_join(summarised_by_rel_matches, rei_sub_scale_summary)
analogy_rei_joint
```

3.)
```{r}
analogy_rei_joint %>%
  ggplot(aes(y = score , x= rel, color = sub_type))+
  geom_point() +
  geom_smooth(se=FALSE) +
  theme_minimal() +
  labs(y = "REI Score", x = "number of relational matches", title = "Correlation between relational matches, score, and sub type")
```

# Week 6
1.)
```{r}
probability_task_data <- read.csv("tidy_data/MFIndD_probtask.csv")
probability_task_data
```
2.)
```{r}
#probability_task_data %>%
 # summarize(count = n_distinct(condition))

condition_vector <- probability_task_data$condition %>%
  unique()

length(condition_vector)

condition_vector

```
I did the above code two ways, the part in the comment is finding the number of unqiue values first separate from listing them, and the second way uses only one statement to make a vector of the values and its lenght as the number of unqiue items. I figures the second way was more efficient, but kept the first because it was my initial approach.

rt = columnd of reaction time in ms

```{r}
mean_vector = c(0,0,0,0)

number_of_entries = c(0,0,0,0)

for(i in seq_along(probability_task_data$condition)){
  
  if(probability_task_data$condition[i] == condition_vector[1]){ 
   mean_vector[1]<- mean_vector[1]+ probability_task_data$rt[i]
   number_of_entries[1] = number_of_entries[1]+1
  }else if(probability_task_data$condition[i] == condition_vector[2]){
    mean_vector[2]<- mean_vector[2]+ probability_task_data$rt[i]
    number_of_entries[2] = number_of_entries[2]+1
  }else if(probability_task_data$condition[i] == condition_vector[3]){
    mean_vector[3]<- mean_vector[3]+ probability_task_data$rt[i]
    number_of_entries[3] = number_of_entries[3]+1
  }else if(probability_task_data$condition[i] == condition_vector[4]){
    mean_vector[4]<- mean_vector[4]+ probability_task_data$rt[i]
    number_of_entries[4] = number_of_entries[4]+1
  }
    
}

mean_vector <- mean_vector/number_of_entries
mean_vector
```

3.)
```{r}
probability_task_data %>%
  group_by(condition) %>%
  summarise(mean_rt = mean(rt), overall_accuracy = mean(correct))
```

```{r}
means_using_across <- probability_task_data %>%
  group_by(condition) %>%
  summarise(across(c(rt,correct), mean))
means_using_across
```

# Week 7

1.)
```{r}
probability_task_data %>%
group_by(condition) %>%
summarise(across(c(rt, correct), mean)) %>%
pivot_longer(c(rt, correct)) %>%
ggplot(aes(y = value, x = condition)) +
geom_point(color = "red") +
facet_wrap(~name, scales = "free")
```


1a).

From the first plot, we can see from the title that it graphs the relationship between condition and the value of correctness. Thus, the first plot shows us how accurate participants were across conditions. From this, we can tell that particpants were considerably more accurate in the "blob_stacked" and "dots_EqSizeRand" conditions than they were in the "blob_shifted" and "dots_EqSizeSep" conditions. The right plot is titled "rt", meaning it plots the reaction time for each of the conditions.This plot shows that the reaction time for the "blob_stacked" condition is much faster than all the other conditions at just below 850, with "dots_EqSizeRand" being the second closest with an average around 880, and the conditions of "blob_shifted" and "dots_EqSizeSep" being very close to each other around 890. The combinations of both plots shows that particpants tended to react faster and with more accuracy for the conditions of "blob_stacked" and "dots_EqSizeRand". With these two conditions, the faster reaction was also more accurate. 

1b).

The first thing I noticed for both graphs is how there were 2 pairs of points, the points in each pair were close to each other but the pairs themselves were very far apart. I think this was the first thing I noticed because the distance between pairs was very large which made it apparent, and also at a distance both plots have the same pattern of pairs being very far apart.

1c).

The information I think is hard to see in the plot is the condition that each point relates to. On my screen the labels for conditions are long and the words squish together below the x axis for both plots, making it hard to read and decipher what the words say. This squishing of words makes it hard. In the same difficulty of discerning conditions, the points are all the same color. Since both plots have the same conditions, discerning condition by color and having one key would be easier to read the labels and tell which point was which. 

2).

For this problem, I am reading in the raw data again from the csv because my last week's grade was low so I wanted to avoid any past errors propagating into this week.

```{r}
probability_data <- read.csv("tidy_data/MFIndD_probtask.csv")
prop_data <- probability_data %>%
  group_by(condition, SubID) %>%
  summarise(prop_corr = mean(correct)) %>%
  ggplot(aes(y = prop_corr, x = condition, color = condition)) +
  geom_jitter(width = 0.2, height = 0,  alpha = 0.6)+
  labs(title = "Proportion of correct by condition")
prob_data
  
```
I added geom_jitter to separate the points and make it easier to read. I also changed the colors of the points to make the difference between condition types easier to read apart. I also added a title to make it more clear what the graph was saying as opposed to just the "condition" on the first graph.

I had some things I was unsure about for this question so i'll list them here, hopefully my explanation will save some points, even if not please explain in the submission comments. I though of using mutate to add the new column to the raw data because thats what the wording of the question led me to believe, however, either summarise or mutate would result in the same end graph, summarise just gets rid of the excess data. 

3.)
```{r}

probability_data <- read.csv("tidy_data/MFIndD_probtask.csv")
prob_data <- probability_data %>%
  group_by(condition, SubID) %>%
  summarise(prop_corr = mean(correct)) %>%
  ggplot(aes(y = condition, x = prop_corr, color = condition)) +
  geom_jitter(width = 0.2, height = 0,  alpha = 0.6)+
  labs(title = "Proportion of correct by condition") +
  geom_dotsinterval()
prob_data
```

Including intervals helps this plot show things the other two don't. The other plot showed only the mean, but by showing distributions we can see frequencies. By seeing where the interval rises and falls, we can see that there were certain proportions than many participants showed, and others that only very few showed. For example, the first graph shows that the mean for the "blob_shifted" condition was around .6, however this plot shows  a very low frequency there, and shows that there were much more participants that were around .55 and .7, with a dip at .6. This information could not be told from the other two graphs.


# Week 8

For the below problem, the part in comments was my initial approach. However it had many decimals and firstly did not match your output, and was secondly hard to read. To match your output, I chose to not use the across() function, so that i could round the mean of both columns to more closley resemble your example output as well as make it easier to read.

2.)
```{r}
#mean_rt_correct_data <-probability_data %>%
  #group_by(SubID, condition) %>%
 #summarise(across(c(rt, correct), mean))
mean_rt_correct_data <-probability_data %>%
  group_by(SubID, condition) %>%
 summarise(rt = round(mean(rt)),correct= round(mean(correct),3))
mean_rt_correct_data
```
3.)

```{r}
#Separate condition by colors
mean_rt_correct_data %>%
  ggplot(aes(y = correct, x = rt, color = condition)) +
  geom_point() +
  labs(title = "Relationship between reaction time and accuracy", x = "Reaction Time", y = "Accuracy")
```

```{r}
#Separate condtion by plots
mean_rt_correct_data %>%
  ggplot(aes(y = correct, x = rt)) +
  geom_point() +
  labs(y = "Accuracy", x = "Reaction Time") +
  facet_wrap(~condition)
```
4.)
There was something to be gathered from each of the plots made in problem 3.

*Condition by color plot:* This plot showed that besides a few outliers, the relation of reaction time and accuracy was most similar for all conditions between a reaction time of 500-1000 and an accuracy between .5-.7. The density and variety of colors around this area showed that many of the conditions had a similar relationship in that general domain.

**Condition separated by plots:** These plots separated all of the conditions more clearly and shows how each one changed its relationship as reaction time changed. From this plot we can tell that for a condition like blob_shifted, as reaction time increased passed 1000, accuracy stayed fairly high and close to each over: remaining between .7 and .8. While the condition of blob_stacked had more variation, some points around .6 and some around.9. Furthermore, we could see that some conditions did not end up having as long reaction time as others, we can see this because blob_shifted had some reaction times beyond 1500, while none of the other conditions did.
